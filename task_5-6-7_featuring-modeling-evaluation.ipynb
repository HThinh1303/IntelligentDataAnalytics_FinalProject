{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import re\n",
    "from transformers import AutoTokenizer ,BertForSequenceClassification, AdamW\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read train data\n",
    "train_data=pd.read_csv(\"new_train.csv\")\n",
    "# read test data\n",
    "test_data=pd.read_csv(\"new_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>our deed   reason   earthquak may ah forgiv us</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>forest fire near la rong sask canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all resid ask  shelter  place  beg notifi  off...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>peopl receiv wildfir evacu order  california</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>just got sent  photo  rubi alka  smoke  wildfi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0   our deed   reason   earthquak may ah forgiv us        1\n",
       "1              forest fire near la rong sask canada       1\n",
       "2  all resid ask  shelter  place  beg notifi  off...      1\n",
       "3      peopl receiv wildfir evacu order  california       1\n",
       "4  just got sent  photo  rubi alka  smoke  wildfi...      1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>just happen terribl car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>heard  earthquak  differ citi stay safe everyon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>forest fire  spot pond gees  flee across  st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>apocalyps light spokan wildfir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>typhoon soudelor kill  cha  taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text\n",
       "0   0                     just happen terribl car crash \n",
       "1   2   heard  earthquak  differ citi stay safe everyon \n",
       "2   3    forest fire  spot pond gees  flee across  st...\n",
       "3   9                    apocalyps light spokan wildfir \n",
       "4  11                typhoon soudelor kill  cha  taiwan "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=train_data.values.tolist()\n",
    "test_data=test_data.values.tolist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mydata(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = train_test_split(train_data, test_size = 0.24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=Mydata(train)\n",
    "valid=Mydata(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model max_length:  512\n"
     ]
    }
   ],
   "source": [
    "print(\"Model max_length: \", tokenizer.model_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data: list[tuple[str, int]]):\n",
    "    texts = []\n",
    "    labels = []\n",
    "    for content, label in data:\n",
    "        texts.append(content)\n",
    "        labels.append(label)    \n",
    "    input_ids = tokenizer.batch_encode_plus(texts, padding = True, truncation = True)['input_ids']\n",
    "    input_ids = torch.tensor(input_ids)\n",
    "    labels = torch.tensor(labels)\n",
    "    return input_ids, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(dataset = train, batch_size = 32, collate_fn = collate_fn, shuffle = True)\n",
    "valid_dataloader = torch.utils.data.DataLoader(dataset = valid, batch_size = 32, collate_fn = collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101,  2128,  4168,  ...,     0,     0,     0],\n",
      "        [  101, 19387,  3602,  ...,     0,     0,     0],\n",
      "        [  101,  8108,  2377,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  9389,  2063,  ...,     0,     0,     0],\n",
      "        [  101,  5034,  2213,  ...,  8909,   102,     0],\n",
      "        [  101,  1058,  2419,  ...,  2615,  7186,   102]]) tensor([0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
      "        1, 0, 0, 0, 0, 0, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "for input_ids, labels in train_dataloader:\n",
    "    print(input_ids, labels)\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyBertForClassification(torch.nn.Module):\n",
    "    def __init__(self, num_labels) -> None:\n",
    "        super().__init__()\n",
    "        self.bert = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_labels)\n",
    "    def forward(self, input_ids, labels):\n",
    "        outputs = self.bert(input_ids=input_ids, labels=labels)\n",
    "        probs = torch.softmax(outputs['logits'], dim = -1)\n",
    "        preds = torch.argmax(probs, dim = -1)\n",
    "        outputs['preds'] = preds\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = MyBertForClassification(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 4e-6\n",
    "EPOCH = 4\n",
    "LOG_STEP = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loader Step: 181\n",
      "Valid Loader Step: 58\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train Loader Step: {len(train_dataloader)}\")\n",
    "print(f\"Valid Loader Step: {len(valid_dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:\n",
      "[Epoch 1, Batch 30] loss: 0.670\n",
      "[Epoch 1, Batch 60] loss: 0.587\n",
      "[Epoch 1, Batch 90] loss: 0.528\n",
      "[Epoch 1, Batch 120] loss: 0.537\n",
      "[Epoch 1, Batch 150] loss: 0.510\n",
      "[Epoch 1, Batch 180] loss: 0.463\n",
      "Valid loss: 0.48113364084013577\n",
      "Epoch 1:\n",
      "[Epoch 2, Batch 30] loss: 0.381\n",
      "[Epoch 2, Batch 60] loss: 0.423\n",
      "[Epoch 2, Batch 90] loss: 0.439\n",
      "[Epoch 2, Batch 120] loss: 0.408\n",
      "[Epoch 2, Batch 150] loss: 0.417\n",
      "[Epoch 2, Batch 180] loss: 0.406\n",
      "Valid loss: 0.42330224889105766\n",
      "Epoch 2:\n",
      "[Epoch 3, Batch 30] loss: 0.293\n",
      "[Epoch 3, Batch 60] loss: 0.315\n",
      "[Epoch 3, Batch 90] loss: 0.283\n",
      "[Epoch 3, Batch 120] loss: 0.334\n",
      "[Epoch 3, Batch 150] loss: 0.360\n",
      "[Epoch 3, Batch 180] loss: 0.322\n",
      "Valid loss: 0.44283307934629507\n",
      "Epoch 3:\n",
      "[Epoch 4, Batch 30] loss: 0.223\n",
      "[Epoch 4, Batch 60] loss: 0.244\n",
      "[Epoch 4, Batch 90] loss: 0.207\n",
      "[Epoch 4, Batch 120] loss: 0.223\n",
      "[Epoch 4, Batch 150] loss: 0.223\n",
      "[Epoch 4, Batch 180] loss: 0.254\n",
      "Valid loss: 0.5008486488769794\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCH):\n",
    "    running_loss = 0.0\n",
    "    print(f\"Epoch {epoch}:\")\n",
    "    model.train()  # Chuyển sang chế độ huấn luyện\n",
    "    for i, (input_id, label) in enumerate(train_dataloader):\n",
    "        input_ids = input_id\n",
    "        labels = label\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(input_ids, labels)\n",
    "        loss = outputs['loss']\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if i % LOG_STEP == LOG_STEP-1:\n",
    "            print('[Epoch %d, Batch %d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / LOG_STEP))\n",
    "            running_loss = 0.0\n",
    "\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for step, (input_ids, labels) in enumerate(valid_dataloader):\n",
    "            outputs = model(input_ids, labels)\n",
    "            loss = outputs['loss']\n",
    "            valid_loss += loss.item()\n",
    "    print(f\"Valid loss: {valid_loss / len(valid_dataloader)}\")\n",
    "\n",
    "# Lưu mô hình\n",
    "torch.save(model.state_dict(), 'bert_classifier.pth')\n",
    "# model.load_state_dict(torch.load('bert_classifier.pth'))\n",
    "# model.eval()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data: list[tuple[str, int]]):\n",
    "    texts = []\n",
    "    ids = []\n",
    "    for id, content in data:\n",
    "        texts.append(content)\n",
    "        ids.append(id)    \n",
    "    input_ids = tokenizer.batch_encode_plus(texts, padding = True, truncation = True)['input_ids']\n",
    "    input_ids = torch.tensor(input_ids)\n",
    "    ids = torch.tensor(ids)\n",
    "    return input_ids, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs,ids=collate_fn(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=Mydata(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = torch.utils.data.DataLoader(dataset = test_data, batch_size = 1, collate_fn = collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_test={\n",
    "    'id':[],\n",
    "    'target':[]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for step, (input_ids, idx) in enumerate(test_dataloader):\n",
    "        outputs = model(input_ids=input_ids, labels=None)\n",
    "        preds = outputs['preds']\n",
    "        span = preds[0].item()\n",
    "        result_test['id'].append(idx.item())\n",
    "        result_test['target'].append(span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(result_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"result1.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
